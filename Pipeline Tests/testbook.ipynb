{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing Dependencies\n",
    "\n",
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Dimensionality Reduction\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import matthews_corrcoef, mean_squared_error, accuracy_score, make_scorer\n",
    "\n",
    "# Model Persistence\n",
    "from joblib import dump, load\n",
    "\n",
    "# Plotter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Argument Parser\n",
    "import argparse\n",
    "\n",
    "# Write to a log file\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the logger\n",
    "def log_files(logname):\n",
    "    \n",
    "    # Instantiate the logger and set the formatting and minimum level to DEBUG.\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    formatter = logging.Formatter('%(asctime)s | %(levelname)s | %(message)s')\n",
    "\n",
    "    # Display the logs in the output\n",
    "    stdout_handler = logging.StreamHandler(sys.stdout)\n",
    "    stdout_handler.setLevel(logging.DEBUG)\n",
    "    stdout_handler.setFormatter(formatter)\n",
    "\n",
    "    # Write the logs to a file\n",
    "    file_handler = logging.FileHandler(logname)\n",
    "    file_handler.setLevel(logging.INFO)\n",
    "    file_handler.setFormatter(formatter)\n",
    "\n",
    "    # Adding the file and output handlers to the logger.\n",
    "    logger.addHandler(file_handler)\n",
    "    #logger.addHandler(stdout_handler)\n",
    "\n",
    "    return logger\n",
    "\n",
    "logger = log_files('testbook.log')\n",
    "\n",
    "## Logarithmically scalling the values.\n",
    "def rescale(array=np.array(0), destination_interval=(-5,5)):\n",
    "\n",
    "    # Rescaling the values and saving the initial range.\n",
    "    array = np.log(array)\n",
    "    saved_range = (array.min(), array.max())\n",
    "    array = np.interp(array, saved_range, destination_interval)\n",
    "\n",
    "    return array, saved_range\n",
    "\n",
    "## Inverse of the rescale function to rescale the outputs.\n",
    "def unscale(array, destination_interval, source_interval=(-5,5)):\n",
    "\n",
    "    # Undoing the previous rescaling.\n",
    "    array = np.interp(array, source_interval, destination_interval)\n",
    "    array = np.exp(array)\n",
    "\n",
    "    return array\n",
    "\n",
    "## Import the dataset\n",
    "def import_data(threshold):\n",
    "\n",
    "    # Importing the full KI set into a dataframe.\n",
    "    path = os.getcwd()\n",
    "    df = pd.read_csv(path + '/PositivePeptide_Ki.csv')\n",
    "    logger.debug('The full dataset has %i examples.' %(len(df)))\n",
    "\n",
    "    # Rescaling the dataframe in the log10 (-5,5) range.\n",
    "    df['KI (nM) rescaled'], base_range  = rescale(df['KI (nM)'], destination_interval=(-5,5))\n",
    "\n",
    "    # Creates a column in our dataframe to classify into 3 separate buckets.  A 'small' and 'large' bucket\n",
    "    # based on the threshold, and a 'do not measure bucket' for anything with a KI value of > 4000    \n",
    "    df['Bucket'] = pd.cut(x=df['KI (nM)'], bins=(0, threshold, 4000, float('inf')), labels=(0,1,2))\n",
    "\n",
    "    return df, base_range\n",
    "\n",
    "def hyperparameter_optimizer(x, y, params, model=SVC()):\n",
    "\n",
    "    # Use GridsearchCV to get the optimized parameters.\n",
    "    logger.debug('GridSearchCV Starting')\n",
    "    clf = GridSearchCV(model, params, scoring=make_scorer(matthews_corrcoef), cv=5, n_jobs=-1)\n",
    "    clf.fit(x,y)\n",
    "\n",
    "    # Showing the best paramets found on the development set.\n",
    "    logger.info('Best parameter set: %s\\n' %(clf.best_params_))\n",
    "\n",
    "    # Testing on the development set.\n",
    "    #logger.debug('Grid scores on development set:')\n",
    "    #logger.debug('')\n",
    "    #means = clf.cv_results_['mean_test_score']\n",
    "    #stds = clf.cv_results_['std_test_score']\n",
    "    #for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    #    logger.debug('%0.3f (+/-%0.03f) for %r' % (mean, std*2, params))\n",
    "    logger.debug('GridSearchCV Finished')\n",
    "\n",
    "    # Save the best parameters.\n",
    "    bestvals = clf.best_params_\n",
    "\n",
    "    return bestvals\n",
    "\n",
    "def postprocessing(df, x, y, params, model=SVC()):\n",
    "\n",
    "    # Train our model\n",
    "    seeds = [33, 42, 55, 68, 74]\n",
    "    i = 0\n",
    "\n",
    "    # Initialize the sums of the acc/mcc's.\n",
    "    train_accuracy_sum = 0\n",
    "    train_mcc_sum = 0\n",
    "    valid_accuracy_sum = 0\n",
    "    valid_mcc_sum = 0\n",
    "\n",
    "    # Optimize the hyperparameters.\n",
    "    optimized_features = hyperparameter_optimizer(x, y, params, model)\n",
    "    model.set_params(**optimized_features)\n",
    "\n",
    "    for seed in seeds:\n",
    "        i += 1\n",
    "        logger.debug('Training:')\n",
    "        x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=seed)\n",
    "        model.fit(x_train, y_train)\n",
    "        logger.debug('Training Finished.')\n",
    "\n",
    "        # Test the model on the training set.\n",
    "        y_train_pred = model.predict(x_train)\n",
    "        train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "        train_mcc = matthews_corrcoef(y_train, y_train_pred)\n",
    "\n",
    "        # Test the model on the validation set.\n",
    "        y_valid_pred = model.predict(x_valid)\n",
    "        valid_accuracy = accuracy_score(y_valid, y_valid_pred)\n",
    "        valid_mcc = matthews_corrcoef(y_valid, y_valid_pred)\n",
    "\n",
    "        # Log the individual folds\n",
    "        logger.info('Training Accuracy: %3.3f, Training MCC: %3.3f, Validation Accuracy: %3.3f, '\n",
    "                    'Validation MCC: %3.3f, Fold: %i\\n'\n",
    "                    %(train_accuracy, train_mcc, valid_accuracy, valid_mcc, i))\n",
    "\n",
    "        # Save the results into a dataframe and display them in the logger file.\n",
    "        trial = pd.DataFrame()\n",
    "        trial['y_valid'] = y_valid\n",
    "        trial['y_valid_pred'] = y_valid_pred\n",
    "        trial['KI (nM)'] = df['KI (nM)'][trial.index]\n",
    "        logger.info('Actual: | Predicted: | KI (nM)')\n",
    "        for valid, pred, ki in zip(trial['y_valid'], trial['y_valid_pred'], trial['KI (nM)']):\n",
    "            logger.info(' %i      |  %i         | %f' %(valid, pred, ki))\n",
    "        logger.info('Fold %i finished:\\n' %(i))\n",
    "\n",
    "        # Add to the sums\n",
    "        train_accuracy_sum += train_accuracy\n",
    "        train_mcc_sum += train_mcc\n",
    "        valid_accuracy_sum += valid_accuracy\n",
    "        valid_mcc_sum += valid_mcc\n",
    "\n",
    "        # Save the validation set with predicted and actual results.\n",
    "    \n",
    "    # Calculate the averages\n",
    "    train_accuracy_avg = train_accuracy_sum/5\n",
    "    train_mcc_avg = train_mcc_sum/5\n",
    "    valid_accuracy_avg = valid_accuracy_sum/5\n",
    "    valid_mcc_avg = valid_mcc_sum/5\n",
    "\n",
    "    # Log the average scores for all the folds\n",
    "    logger.info('AVG Training Accuracy: %3.3f, AVG Training MCC: %3.3f, AVG Validation Accuracy: %3.3f, '\n",
    "                'AVG Validation MCC: %3.3f\\n' %(train_accuracy_avg, train_mcc_avg, valid_accuracy_avg, valid_mcc_avg))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "180 fits failed out of a total of 720.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan  0.10841657  0.14014176  0.09642994\n",
      " -0.06719183  0.1756416   0.04732374  0.10151737  0.1724713   0.0417139\n",
      "         nan         nan         nan  0.0505449   0.13546768  0.20172206\n",
      "  0.17723482  0.09432954 -0.0757649   0.07859164  0.0539071   0.02253827\n",
      "         nan         nan         nan  0.03627391  0.05133667  0.02756083\n",
      " -0.03927512  0.143445    0.08185027 -0.04892875  0.07133983  0.10017907\n",
      "         nan         nan         nan -0.0008458   0.09231306  0.07783414\n",
      "  0.18336886  0.12538341  0.05280027  0.00178993  0.11626694  0.08683073\n",
      "         nan         nan         nan  0.07791236  0.08244623  0.10545123\n",
      "  0.0269765  -0.0149959   0.05749898  0.22261467  0.17391265  0.11177635\n",
      "         nan         nan         nan  0.21908722  0.1305388   0.06927282\n",
      "  0.08256911  0.14937598  0.11138015  0.06694545  0.05683985  0.15984013\n",
      "         nan         nan         nan  0.21591145  0.17820372  0.11729943\n",
      "  0.17128685  0.20541608  0.23437852  0.23242095  0.10087283  0.08309926\n",
      "         nan         nan         nan  0.06265438  0.16875725  0.23437852\n",
      "  0.24093275  0.16875725  0.10087283  0.05292736  0.12121482  0.19435753\n",
      "         nan         nan         nan  0.01894631  0.1429782   0.18649667\n",
      "  0.20009108  0.15984013  0.25637043  0.13295169  0.08309926  0.14576424\n",
      "         nan         nan         nan  0.23437852  0.08309926  0.23437852\n",
      "  0.19141282  0.23437852  0.23437852  0.1664941   0.08309926  0.12647311\n",
      "         nan         nan         nan  0.19435753  0.2261002   0.17391265\n",
      "  0.20837501  0.18913808  0.27975673  0.07787981  0.23437852  0.23437852\n",
      "         nan         nan         nan  0.17820372  0.19468636  0.15098368\n",
      "  0.06643296  0.17391265  0.1664941   0.04915705  0.11138015  0.08686957]\n",
      "  warnings.warn(\n",
      "c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "180 fits failed out of a total of 720.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan  0.0224555   0.24522456  0.06748506\n",
      "  0.16861811  0.31925087  0.17819375  0.22382565  0.23056397  0.01444567\n",
      "         nan         nan         nan  0.2324026   0.14678959  0.30940814\n",
      "  0.10122251  0.25615992  0.24639643  0.09425669  0.17664287  0.21022327\n",
      "         nan         nan         nan  0.10089561  0.05390519  0.16204527\n",
      "  0.30068065  0.10027914  0.28286238  0.05289856  0.24335372  0.22200573\n",
      "         nan         nan         nan  0.13592271  0.25854941  0.27015793\n",
      "  0.21967344  0.21142176  0.10624545  0.18981115  0.20993914  0.14031999\n",
      "         nan         nan         nan  0.18999977  0.22228822  0.24715808\n",
      "  0.16016617  0.25028489  0.15299358  0.17423374  0.13553346  0.2236975\n",
      "         nan         nan         nan  0.2052871   0.07354343  0.18771375\n",
      "  0.2153016   0.26596477  0.16528158  0.27378275  0.14657773  0.07179314\n",
      "         nan         nan         nan  0.12509429  0.11108706  0.16277662\n",
      "  0.16807194  0.13053749  0.18908191  0.29590409  0.22363633  0.18658362\n",
      "         nan         nan         nan  0.34290899  0.13583281  0.17951146\n",
      "  0.30386436  0.13567539  0.26528934  0.11448244  0.08916017  0.16961252\n",
      "         nan         nan         nan -0.01411101  0.14769962  0.13393959\n",
      "  0.18774725  0.13991928  0.10659197  0.21415786  0.15575191  0.17198412\n",
      "         nan         nan         nan  0.12910112  0.19187894  0.16245445\n",
      "  0.22057925  0.19187894  0.19187894  0.17272302  0.14316516  0.22802069\n",
      "         nan         nan         nan  0.17082979  0.2211889   0.1387808\n",
      "  0.13363327  0.19183149  0.20575427  0.13567031  0.14505142  0.25976337\n",
      "         nan         nan         nan  0.15543484  0.17727944  0.22586722\n",
      "  0.24113996  0.13054383  0.20182401  0.24172757  0.23033887  0.24691269]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def sfs_pca(threshold):\n",
    "    # Import the data and create our logger.\n",
    "    df, _ = import_data(threshold)\n",
    "\n",
    "    ## Model Loading for Forward Selection and PCA\n",
    "    # SVC w/RBF Kernel\n",
    "    sfs_rbf = load(path + '/sfs-pca/SVC with RBF Kernel %2.2f fs.joblib' %(threshold))\n",
    "    pca_rbf = load(path + '/sfs-pca/SVC with RBF Kernel %2.2f pca.joblib' %(threshold))\n",
    "\n",
    "    #XGBoost Classifier\n",
    "    sfs_xgb = load(path + '/sfs-pca/XGBoost Classifier %2.2f fs.joblib' %(threshold))\n",
    "    pca_xgb = load(path + '/sfs-pca/XGBoost Classifier %2.2f pca.joblib' %(threshold))\n",
    "\n",
    "    #Random Forest Classifier\n",
    "    sfs_rf = load(path + '/sfs-pca/Random Forest Classifier %2.2f fs.joblib' %(threshold))\n",
    "    pca_rf = load(path + '/sfs-pca/Random Forest Classifier %2.2f pca.joblib' %(threshold))\n",
    "\n",
    "    # Put the various elements in arrays.\n",
    "    sfs_models = [sfs_rbf, sfs_xgb, sfs_rf]\n",
    "    pca_models = [pca_rbf, pca_xgb, pca_rf]\n",
    "    models = [SVC(kernel='rbf'), XGBClassifier(), RandomForestClassifier()]\n",
    "    names = ['SVC w/RBF Kernel', 'XGBoost Classifier', 'Random Forest Classifier']\n",
    "\n",
    "    # Set our parameters and put them in an array\n",
    "    rbf_params = {'gamma': [1e-2, 1e-3, 1e-4], 'C': [1, 10, 100, 1000]}\n",
    "    xgb_params = {'n_estimators': [50, 100, 150], 'max_depth': [1, 2, 3, 4]}\n",
    "    rf_params = {'class_weight': ['balanced'], 'n_estimators': [50, 100, 150], 'max_depth': [1, 2, 3, 4], \n",
    "                    'min_samples_leaf': [1, 2, 3], 'min_samples_split': [1, 2, 3, 4]}\n",
    "    params_list = [rbf_params, xgb_params, rf_params]\n",
    "\n",
    "    # Zip them up, and then proceed with model analysis.'\n",
    "    logger.info('sfs-pca pipeline:\\n')\n",
    "    for sfs, pca, model, params, name in zip(sfs_models, pca_models, models, params_list, names):\n",
    "\n",
    "        # Reset the variables\n",
    "        x = df[df.columns[1:573]]\n",
    "        y = df['Bucket']\n",
    "\n",
    "        # Apply the transformations\n",
    "        x = sfs.transform(x)\n",
    "        x = pca.transform(x)\n",
    "\n",
    "        # Train the and display results of the gridsearchcv\n",
    "        logger.info('Results for %s with a threshold set to %i\\n' %(name, threshold))\n",
    "        postprocessing(df, x, y, params=params, model=model)\n",
    "\n",
    "sfs_pca(threshold=0.01)\n",
    "sfs_pca(threshold=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "180 fits failed out of a total of 720.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.02027398 0.14662871 0.09957852\n",
      " 0.21668884 0.22227274 0.14006526 0.03395661 0.23172482 0.07531243\n",
      "        nan        nan        nan 0.17033435 0.20828624 0.12934084\n",
      " 0.22502919 0.14046971 0.26185373 0.15905448 0.0536289  0.23651891\n",
      "        nan        nan        nan 0.24817108 0.29367469 0.13879804\n",
      " 0.22370315 0.17432317 0.24095232 0.18915708 0.02221881 0.21146444\n",
      "        nan        nan        nan 0.23248838 0.22558234 0.18164461\n",
      " 0.10602824 0.18624496 0.22919467 0.41900211 0.2210162  0.3187713\n",
      "        nan        nan        nan 0.14666168 0.14841788 0.20985144\n",
      " 0.32945509 0.23307486 0.17089381 0.17355157 0.3551922  0.25186556\n",
      "        nan        nan        nan 0.3076918  0.13201455 0.18463882\n",
      " 0.21708161 0.2646282  0.19283431 0.22453496 0.26402273 0.31408202\n",
      "        nan        nan        nan 0.25361677 0.21380103 0.38804138\n",
      " 0.37539666 0.32694782 0.38522944 0.20276298 0.29169683 0.34303747\n",
      "        nan        nan        nan 0.24336991 0.25839839 0.25896146\n",
      " 0.22768641 0.28592835 0.26523377 0.25702251 0.32274171 0.26616915\n",
      "        nan        nan        nan 0.10510291 0.17611114 0.37044369\n",
      " 0.14071197 0.27157506 0.30102701 0.19904655 0.25064476 0.16122479\n",
      "        nan        nan        nan 0.23706786 0.23437852 0.28349813\n",
      " 0.29314639 0.3441827  0.38804138 0.19721702 0.31315639 0.35138256\n",
      "        nan        nan        nan 0.2421259  0.30020791 0.35171139\n",
      " 0.23419789 0.24797612 0.34642996 0.23433968 0.2291217  0.26697542\n",
      "        nan        nan        nan 0.30791629 0.24707168 0.28418671\n",
      " 0.20016289 0.29206782 0.28839282 0.28353868 0.3790965  0.30413142]\n",
      "  warnings.warn(\n",
      "c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "180 fits failed out of a total of 720.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.15543247 0.28807693 0.28529942\n",
      " 0.0221464  0.14486661 0.26877199 0.24872203 0.18948337 0.26036129\n",
      "        nan        nan        nan 0.22469289 0.27875358 0.25015465\n",
      " 0.33550066 0.29189837 0.23949328 0.20883107 0.33153861 0.23574662\n",
      "        nan        nan        nan 0.20071548 0.22652385 0.27432169\n",
      " 0.23975882 0.19000675 0.30797316 0.15183857 0.24131497 0.33909236\n",
      "        nan        nan        nan 0.28585353 0.37191549 0.36810746\n",
      " 0.28015415 0.21110813 0.33266485 0.17133545 0.28123751 0.3012196\n",
      "        nan        nan        nan 0.26904631 0.3034515  0.36721618\n",
      " 0.34291945 0.33214706 0.26121212 0.31726181 0.28230371 0.28789558\n",
      "        nan        nan        nan 0.24355828 0.18763462 0.3139866\n",
      " 0.29324944 0.29631832 0.21069012 0.05343312 0.29700497 0.47963441\n",
      "        nan        nan        nan 0.31902504 0.29318    0.33075641\n",
      " 0.36046105 0.08077386 0.33143407 0.37549215 0.29047654 0.1625328\n",
      "        nan        nan        nan 0.31629763 0.38309753 0.28815311\n",
      " 0.23407915 0.29099202 0.24672999 0.33178846 0.38867763 0.26815399\n",
      "        nan        nan        nan 0.31855855 0.26461145 0.33823217\n",
      " 0.30692802 0.46564428 0.25071093 0.32041    0.39979528 0.38641984\n",
      "        nan        nan        nan 0.32940517 0.24300802 0.32154152\n",
      " 0.11999818 0.22374885 0.19040095 0.19014593 0.24045574 0.34646055\n",
      "        nan        nan        nan 0.2597351  0.31339177 0.40902625\n",
      " 0.25696391 0.34120587 0.28187293 0.42644788 0.26920932 0.34897586\n",
      "        nan        nan        nan 0.22160683 0.29632008 0.22195762\n",
      " 0.28169407 0.2718529  0.4042366  0.15899301 0.37650764 0.20638961]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def pca_sfs(threshold):\n",
    "    # Import the data and create our logger.\n",
    "    df, _ = import_data(threshold)\n",
    "\n",
    "    ## Model Loading for Forward Selection and PCA\n",
    "    # SVC w/RBF Kernel\n",
    "    pca_rbf = load(path + '/pca-sfs/SVC with RBF Kernel %2.2f pca.joblib' %(threshold))\n",
    "    sfs_rbf = load(path + '/pca-sfs/SVC with RBF Kernel %2.2f fs.joblib' %(threshold))\n",
    "\n",
    "    #XGBoost Classifier\n",
    "    pca_xgb = load(path + '/pca-sfs/XGBoost Classifier %2.2f pca.joblib' %(threshold))\n",
    "    sfs_xgb = load(path + '/pca-sfs/XGBoost Classifier %2.2f fs.joblib' %(threshold))\n",
    "\n",
    "    #Random Forest Classifier\n",
    "    pca_rf = load(path + '/pca-sfs/Random Forest Classifier %2.2f pca.joblib' %(threshold))\n",
    "    sfs_rf = load(path + '/pca-sfs/Random Forest Classifier %2.2f fs.joblib' %(threshold))\n",
    "\n",
    "    # Put the various elements in arrays.\n",
    "    pca_models = [pca_rbf, pca_xgb, pca_rf]\n",
    "    sfs_models = [sfs_rbf, sfs_xgb, sfs_rf]\n",
    "    models = [SVC(kernel='rbf'), XGBClassifier(), RandomForestClassifier()]\n",
    "    names = ['SVC w/RBF Kernel', 'XGBoost Classifier', 'Random Forest Classifier']\n",
    "\n",
    "    # Set our parameters and put them in an array\n",
    "    rbf_params = {'gamma': [1e-2, 1e-3, 1e-4], 'C': [1, 10, 100, 1000]}\n",
    "    xgb_params = {'n_estimators': [50, 100, 150], 'max_depth': [1, 2, 3, 4]}\n",
    "    rf_params = {'class_weight': ['balanced'], 'n_estimators': [50, 100, 150], 'max_depth': [1, 2, 3, 4], \n",
    "                    'min_samples_leaf': [1, 2, 3], 'min_samples_split': [1, 2, 3, 4]}\n",
    "    params_list = [rbf_params, xgb_params, rf_params]\n",
    "\n",
    "    # Zip them up, and then proceed with model analysis.\n",
    "    logger.info('pca-sfs pipeline:\\n')\n",
    "    for sfs, pca, model, params, name in zip(sfs_models, pca_models, models, params_list, names):\n",
    "\n",
    "        # Reset the variables\n",
    "        x = df[df.columns[1:573]]\n",
    "        y = df['Bucket']\n",
    "\n",
    "        # Apply the transformations\n",
    "        x = pca.transform(x)\n",
    "        x = sfs.transform(x)\n",
    "        \n",
    "        # Train the and display results of the gridsearchcv\n",
    "        logger.info('Results for %s with a threshold set to %i\\n' %(name, threshold))\n",
    "        postprocessing(df, x, y, params=params, model=model)\n",
    "\n",
    "pca_sfs(threshold=0.01)\n",
    "pca_sfs(threshold=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "180 fits failed out of a total of 720.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.13454667 0.17449645 0.26373445\n",
      " 0.1529834  0.28278228 0.31183605 0.13596739 0.10210098 0.36569379\n",
      "        nan        nan        nan 0.28391839 0.26523257 0.24189604\n",
      " 0.00291619 0.34849356 0.25061408 0.24635075 0.20049755 0.24787134\n",
      "        nan        nan        nan 0.29485556 0.32972407 0.40235809\n",
      " 0.21367359 0.23948837 0.23389062 0.15776381 0.1588735  0.25899427\n",
      "        nan        nan        nan 0.1419529  0.12541801 0.17988793\n",
      " 0.19391598 0.14437106 0.28181882 0.16565721 0.32215333 0.17421689\n",
      "        nan        nan        nan 0.25639113 0.23232349 0.059496\n",
      " 0.30583596 0.14308585 0.23102786 0.18947115 0.42939003 0.19362642\n",
      "        nan        nan        nan 0.14096447 0.10566172 0.21972152\n",
      " 0.31645942 0.15968421 0.14723082 0.15747073 0.13597859 0.23075396\n",
      "        nan        nan        nan 0.07186638 0.12158249 0.13575592\n",
      " 0.14127489 0.23847106 0.17091547 0.12821455 0.15936022 0.14518756\n",
      "        nan        nan        nan 0.29784084 0.21658614 0.14514872\n",
      " 0.12555816 0.30705199 0.18184639 0.11789632 0.26187851 0.19330244\n",
      "        nan        nan        nan 0.22579691 0.27772628 0.17912977\n",
      " 0.10406993 0.14902266 0.1067029  0.2075383  0.12476782 0.23294979\n",
      "        nan        nan        nan 0.09383803 0.17058664 0.17058664\n",
      " 0.06503058 0.16115501 0.1641406  0.1705478  0.23709514 0.18184639\n",
      "        nan        nan        nan 0.16460141 0.23709514 0.11182203\n",
      " 0.23830758 0.15791249 0.30705199 0.28095641 0.20079943 0.14518756\n",
      "        nan        nan        nan 0.09934471 0.26255944 0.25052835\n",
      " 0.21418709 0.11182203 0.21307198 0.25210963 0.16446943 0.16460141]\n",
      "  warnings.warn(\n",
      "c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "180 fits failed out of a total of 720.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan -0.00372524  0.1319395   0.09927819\n",
      "  0.21667199  0.07174436  0.09767665 -0.01395346 -0.0498328   0.14765287\n",
      "         nan         nan         nan -0.00658829  0.21376244  0.04672019\n",
      " -0.03725676  0.06175725  0.19581801  0.10000517  0.03288575  0.05400892\n",
      "         nan         nan         nan  0.074943    0.02832872  0.17732931\n",
      "  0.01541168  0.06383665 -0.01702946  0.19384137  0.13903727  0.14417113\n",
      "         nan         nan         nan -0.00137849  0.00219953  0.16064326\n",
      "  0.13599969  0.15882269  0.18850856  0.12021983  0.09741809  0.11472625\n",
      "         nan         nan         nan  0.05919784  0.00433605  0.0835999\n",
      " -0.05284793  0.06047924  0.18669604  0.06843111  0.33758651  0.13103302\n",
      "         nan         nan         nan  0.1616751   0.06065927  0.07937043\n",
      "  0.04961689 -0.07869371  0.16689148  0.22575019 -0.0384499   0.10083714\n",
      "         nan         nan         nan  0.12487163  0.23146926  0.06667784\n",
      "  0.32870399 -0.00397076  0.11026891  0.05153549  0.18106039  0.04937316\n",
      "         nan         nan         nan -0.01780949  0.03482776  0.06902717\n",
      "  0.09169683  0.04676885  0.08383131  0.14194248  0.14421112  0.00699909\n",
      "         nan         nan         nan  0.05205003  0.27712371  0.1053251\n",
      "  0.01630093  0.04083548  0.13339564  0.13757973  0.08857064  0.19060859\n",
      "         nan         nan         nan  0.11557895  0.12817305  0.10392763\n",
      "  0.1349858   0.09147425  0.23724327  0.1192053   0.10661053  0.16304334\n",
      "         nan         nan         nan  0.10422016  0.02468303  0.04311047\n",
      "  0.0989079   0.08536911  0.08383627  0.04319973  0.14753818  0.11870656\n",
      "         nan         nan         nan -0.07411984  0.04452455  0.12607406\n",
      "  0.05556097  0.05128657  0.09909009  0.11459399  0.05737655  0.06949042]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def mms_sfs_pca(threshold):\n",
    "    # Import the data and create our logger.\n",
    "    df, _ = import_data(threshold)\n",
    "\n",
    "    ## Model Loading for Forward Selection and PCA\n",
    "    # SVC w/RBF Kernel\n",
    "    sfs_rbf = load(path + '/mms-sfs-pca/SVC with RBF Kernel %2.2f fs.joblib' %(threshold))\n",
    "    pca_rbf = load(path + '/mms-sfs-pca/SVC with RBF Kernel %2.2f pca.joblib' %(threshold))\n",
    "\n",
    "    #XGBoost Classifier\n",
    "    sfs_xgb = load(path + '/mms-sfs-pca/XGBoost Classifier %2.2f fs.joblib' %(threshold))\n",
    "    pca_xgb = load(path + '/mms-sfs-pca/XGBoost Classifier %2.2f pca.joblib' %(threshold))\n",
    "\n",
    "    #Random Forest Classifier\n",
    "    sfs_rf = load(path + '/mms-sfs-pca/Random Forest Classifier %2.2f fs.joblib' %(threshold))\n",
    "    pca_rf = load(path + '/mms-sfs-pca/Random Forest Classifier %2.2f pca.joblib' %(threshold))\n",
    "\n",
    "    # Put the various elements in arrays.\n",
    "    sfs_models = [sfs_rbf, sfs_xgb, sfs_rf]\n",
    "    pca_models = [pca_rbf, pca_xgb, pca_rf]\n",
    "    models = [SVC(kernel='rbf'), XGBClassifier(), RandomForestClassifier()]\n",
    "    names = ['SVC w/RBF Kernel', 'XGBoost Classifier', 'Random Forest Classifier']\n",
    "\n",
    "    # Set our parameters and put them in an array\n",
    "    rbf_params = {'gamma': [1e-2, 1e-3, 1e-4], 'C': [1, 10, 100, 1000]}\n",
    "    xgb_params = {'n_estimators': [50, 100, 150], 'max_depth': [1, 2, 3, 4]}\n",
    "    rf_params = {'class_weight': ['balanced'], 'n_estimators': [50, 100, 150], 'max_depth': [1, 2, 3, 4], \n",
    "                    'min_samples_leaf': [1, 2, 3], 'min_samples_split': [1, 2, 3, 4]}\n",
    "    params_list = [rbf_params, xgb_params, rf_params]\n",
    "\n",
    "    # Zip them up, and then proceed with model analysis.\n",
    "    logger.info('mms-sfs-pca pipeline:\\n')\n",
    "    for sfs, pca, model, params, name in zip(sfs_models, pca_models, models, params_list, names):\n",
    "\n",
    "        # Reset the variables\n",
    "        x = df[df.columns[1:573]]\n",
    "        y = df['Bucket']\n",
    "\n",
    "        # Apply the transformations\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(x,y)\n",
    "        x = scaler.transform(x)\n",
    "        x = sfs.transform(x)\n",
    "        x = pca.transform(x)\n",
    "\n",
    "        # Train the and display results of the gridsearchcv\n",
    "        logger.info('Results for %s with a threshold set to %i\\n' %(name, threshold))\n",
    "        postprocessing(df, x, y, params=params, model=model)\n",
    "\n",
    "mms_sfs_pca(threshold=0.01)\n",
    "mms_sfs_pca(threshold=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "180 fits failed out of a total of 720.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.37596666 0.3793356  0.19316348\n",
      " 0.16130299 0.2541921  0.2391299  0.25315355 0.40507112 0.26951914\n",
      "        nan        nan        nan 0.27499555 0.15443961 0.18141404\n",
      " 0.42759991 0.28834855 0.21598751 0.28658498 0.3143183  0.2885365\n",
      "        nan        nan        nan 0.34404643 0.39713458 0.25626245\n",
      " 0.2241601  0.20786314 0.2931009  0.31883555 0.21682603 0.26083265\n",
      "        nan        nan        nan 0.21005284 0.28824329 0.24568595\n",
      " 0.38390608 0.3520582  0.35976775 0.2595481  0.30704967 0.19166622\n",
      "        nan        nan        nan 0.27905778 0.32830972 0.2474836\n",
      " 0.15510113 0.22611504 0.34541447 0.35798074 0.22062476 0.37970801\n",
      "        nan        nan        nan 0.34021227 0.16842786 0.28333256\n",
      " 0.28632218 0.37232506 0.43171864 0.10529398 0.28098447 0.28511339\n",
      "        nan        nan        nan 0.2294165  0.26951909 0.36082065\n",
      " 0.19662016 0.33892177 0.3097235  0.3070557  0.24474143 0.19967541\n",
      "        nan        nan        nan 0.34592467 0.33262665 0.24752824\n",
      " 0.13983622 0.28969646 0.3348249  0.3667852  0.30769358 0.28969646\n",
      "        nan        nan        nan 0.27644584 0.24162509 0.34017721\n",
      " 0.21844364 0.30251453 0.32150185 0.38622397 0.46282595 0.31671929\n",
      "        nan        nan        nan 0.36448177 0.23226245 0.18934433\n",
      " 0.26481583 0.24116697 0.19100468 0.33889404 0.27096913 0.18934433\n",
      "        nan        nan        nan 0.36870687 0.26919026 0.27133956\n",
      " 0.40213616 0.30308223 0.23433968 0.3697797  0.22942686 0.25722876\n",
      "        nan        nan        nan 0.27902296 0.27371368 0.32966724\n",
      " 0.30348549 0.20984185 0.26919026 0.18466402 0.24319328 0.19842322]\n",
      "  warnings.warn(\n",
      "c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "180 fits failed out of a total of 720.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\a1351\\.conda\\envs\\antithrombin\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.27070175 0.28467842 0.30302681\n",
      " 0.13898571 0.36748679 0.28243007 0.34949967 0.33808284 0.27060958\n",
      "        nan        nan        nan 0.37454937 0.39511805 0.37609016\n",
      " 0.34744459 0.21064962 0.31182383 0.31051477 0.38647802 0.44581313\n",
      "        nan        nan        nan 0.19424991 0.29917343 0.32092494\n",
      " 0.17067643 0.406137   0.20491264 0.26176974 0.3402573  0.30787117\n",
      "        nan        nan        nan 0.23870103 0.33511436 0.41582805\n",
      " 0.25669504 0.31877192 0.37051085 0.30657418 0.44643718 0.37570337\n",
      "        nan        nan        nan 0.28678562 0.33365408 0.35603278\n",
      " 0.44489829 0.37892341 0.50744771 0.29314129 0.45903707 0.41124366\n",
      "        nan        nan        nan 0.44117403 0.37096006 0.37316193\n",
      " 0.37762646 0.38701042 0.46284346 0.31802923 0.33899287 0.37312648\n",
      "        nan        nan        nan 0.35317718 0.36779542 0.29186205\n",
      " 0.19752525 0.37184117 0.32656023 0.30991424 0.3007932  0.32334665\n",
      "        nan        nan        nan 0.35551045 0.28522463 0.41069617\n",
      " 0.39045493 0.27535978 0.4215125  0.40604773 0.34257518 0.31312433\n",
      "        nan        nan        nan 0.43608592 0.30226244 0.35057387\n",
      " 0.30805049 0.35682016 0.30611189 0.36298405 0.40984736 0.36638755\n",
      "        nan        nan        nan 0.3043991  0.33687773 0.36883584\n",
      " 0.29245957 0.28133809 0.23119181 0.28962357 0.25059189 0.33441888\n",
      "        nan        nan        nan 0.26537817 0.33189302 0.4347888\n",
      " 0.24264417 0.21996861 0.31689385 0.3333022  0.31308077 0.35628669\n",
      "        nan        nan        nan 0.39909675 0.34019929 0.31718004\n",
      " 0.34050873 0.33064676 0.32733633 0.23316102 0.40771717 0.3112162 ]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def mms_pca_sfs(threshold):\n",
    "    # Import the data and create our logger.\n",
    "    df, _ = import_data(threshold)\n",
    "\n",
    "    ## Model Loading for Forward Selection and PCA\n",
    "    # SVC w/RBF Kernel\n",
    "    pca_rbf = load(path + '/mms-pca-sfs/SVC with RBF Kernel %2.2f pca.joblib' %(threshold))\n",
    "    sfs_rbf = load(path + '/mms-pca-sfs/SVC with RBF Kernel %2.2f fs.joblib' %(threshold))\n",
    "\n",
    "    #XGBoost Classifier\n",
    "    pca_xgb = load(path + '/mms-pca-sfs/XGBoost Classifier %2.2f pca.joblib' %(threshold))\n",
    "    sfs_xgb = load(path + '/mms-pca-sfs/XGBoost Classifier %2.2f fs.joblib' %(threshold))\n",
    "\n",
    "    #Random Forest Classifier\n",
    "    pca_rf = load(path + '/mms-pca-sfs/Random Forest Classifier %2.2f pca.joblib' %(threshold))\n",
    "    sfs_rf = load(path + '/mms-pca-sfs/Random Forest Classifier %2.2f fs.joblib' %(threshold))\n",
    "\n",
    "    # Put the various elements in arrays.\n",
    "    pca_models = [pca_rbf, pca_xgb, pca_rf]\n",
    "    sfs_models = [sfs_rbf, sfs_xgb, sfs_rf]\n",
    "    models = [SVC(kernel='rbf'), XGBClassifier(), RandomForestClassifier()]\n",
    "    names = ['SVC w/RBF Kernel', 'XGBoost Classifier', 'Random Forest Classifier']\n",
    "\n",
    "    # Set our parameters and put them in an array\n",
    "    rbf_params = {'gamma': [1e-2, 1e-3, 1e-4], 'C': [1, 10, 100, 1000]}\n",
    "    xgb_params = {'n_estimators': [50, 100, 150], 'max_depth': [1, 2, 3, 4]}\n",
    "    rf_params = {'class_weight': ['balanced'], 'n_estimators': [50, 100, 150], 'max_depth': [1, 2, 3, 4], \n",
    "                    'min_samples_leaf': [1, 2, 3], 'min_samples_split': [1, 2, 3, 4]}\n",
    "    params_list = [rbf_params, xgb_params, rf_params]\n",
    "\n",
    "    # Zip them up, and then proceed with model analysis.\n",
    "    logger.info('mms-pca-sfs pipeline:\\n')\n",
    "    for sfs, pca, model, params, name in zip(sfs_models, pca_models, models, params_list, names):\n",
    "\n",
    "        # Reset the variables\n",
    "        x = df[df.columns[1:573]]\n",
    "        y = df['Bucket']\n",
    "\n",
    "        # Apply the transformations\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(x,y)\n",
    "        x = scaler.transform(x)\n",
    "        x = pca.transform(x)\n",
    "        x = sfs.transform(x)\n",
    "        \n",
    "        # Train the and display results of the gridsearchcv\n",
    "        logger.info('Results for %s with a threshold set to %i\\n' %(name, threshold))\n",
    "        postprocessing(df, x, y, params=params, model=model)\n",
    "\n",
    "mms_pca_sfs(threshold=0.01)\n",
    "mms_pca_sfs(threshold=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('antithrombin')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4e80bae16222c7bbbaf59498086a658280d426110f2738491d72ed8ab66400de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
