{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Dependencies\n",
    "import argparse\n",
    "import csv\n",
    "\n",
    "# Write to a log file\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from operator import add\n",
    "\n",
    "# Plotter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Standard libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Model Persistence\n",
    "from joblib import dump, load\n",
    "\n",
    "# Dimensionality Reduction\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (accuracy_score, make_scorer, matthews_corrcoef,\n",
    "                             mean_squared_error)\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import (GridSearchCV, cross_val_score, StratifiedKFold,\n",
    "                                     train_test_split)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC, SVR\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "## Packages to use the .fasta file.\n",
    "# Compute protein descriptors\n",
    "from propy import PyPro\n",
    "from propy import AAComposition\n",
    "from propy import CTD\n",
    "\n",
    "# Build Sequence Object\n",
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "\n",
    "# Read Fasta File\n",
    "from pyfaidx import Fasta\n",
    "\n",
    "# Grouping iterable\n",
    "from itertools import chain\n",
    "\n",
    "# Return file path\n",
    "import glob\n",
    "\n",
    "## Global Variables\n",
    "#\n",
    "PATH = os.getcwd()\n",
    "FOLDS = 5\n",
    "RAND = 42\n",
    "THRESHOLD = 0.01\n",
    "CLF_NAME = 'SVC with RBF Kernel'\n",
    "REG_NAME = 'SVR with RBF Kernel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 8, 12]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(add, [1, 3, 5], [3, 5, 7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inferenceSingleSeqence(seq):\n",
    "    \n",
    "    \"\"\" The inference function gets the protein sequence, trained model, preprocessing function and selected\n",
    "    features as input. \n",
    "    \n",
    "    The function read the sequence as string and extract the peptide features using appropriate packages into \n",
    "    the dataframe.\n",
    "    \n",
    "    The necessary features are selected from the extracted features which then undergoes preprocessing function, the\n",
    "    target value is predicted using trained function and give out the results. \"\"\"\n",
    "    \n",
    "    # empty list to save the features\n",
    "    listing = []\n",
    "    \n",
    "    # Make sure the sequence is a string\n",
    "    s = str(seq)\n",
    "    \n",
    "    # replace the unappropriate peptide sequence to A\n",
    "    s = s.replace('X','A')\n",
    "    s = s.replace('x','A')\n",
    "    s = s.replace('U','A')\n",
    "    s = s.replace('Z','A')\n",
    "    s = s.replace('B','A')\n",
    "    \n",
    "    # Calculating primary features\n",
    "    analysed_seq = ProteinAnalysis(s)\n",
    "    wt = analysed_seq.molecular_weight()\n",
    "    arm = analysed_seq.aromaticity()\n",
    "    instab = analysed_seq.instability_index()\n",
    "    flex = analysed_seq.flexibility()\n",
    "    pI = analysed_seq.isoelectric_point()\n",
    "    \n",
    "    # create a list for the primary features\n",
    "    pFeatures = [seq, s, len(seq), wt, arm, instab, pI]\n",
    "    \n",
    "    # Get secondary structure in a list\n",
    "    sectruc = analysed_seq.secondary_structure_fraction()\n",
    "    sFeatures = list(sectruc)\n",
    "    \n",
    "    # Get Amino Acid Composition (AAC), Composition Transition Distribution (CTD) and Dipeptide Composition (DPC)\n",
    "    resultAAC = AAComposition.CalculateAAComposition(s)\n",
    "    resultCTD = CTD.CalculateCTD(s)\n",
    "    resultDPC = AAComposition.CalculateDipeptideComposition(s)\n",
    "    \n",
    "    # Collect all the features into lists\n",
    "    aacFeatures = [j for i,j in resultAAC.items()]\n",
    "    ctdFeatures = [l for k,l in resultCTD.items()]\n",
    "    dpcFeatures = [n for m,n in resultDPC.items()]\n",
    "    listing.append(pFeatures + sFeatures + aacFeatures + ctdFeatures + dpcFeatures)\n",
    "    \n",
    "    # Collect feature names\n",
    "    name1 = ['Name','Seq' ,'SeqLength','Weight','Aromaticity','Instability','IsoelectricPoint','Helix','Turn','Sheet']\n",
    "    name2 = [i for i,j in resultAAC.items()]\n",
    "    name3 = [k for k,l in resultCTD.items()]\n",
    "    name4 = [m for m,n in resultDPC.items()]\n",
    "    name  = []\n",
    "    name.append(name1+name2+name3+name4)\n",
    "    flatten_list = list(chain.from_iterable(name))\n",
    "    \n",
    "    # create dataframe using all extracted features and the names\n",
    "    allFeatures = pd.DataFrame(listing, columns = flatten_list)\n",
    "\n",
    "    return allFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the test data\n",
    "def test_data():\n",
    "    \"\"\"\n",
    "    Import the full test dataset from the current path.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    None\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x_test: DataFrame containing the test dataset.\n",
    "    \"\"\"\n",
    "    # Import, format, and drop duplicates.\n",
    "    peptide_sequences = pd.read_csv('combined_hits.csv')\n",
    "    peptide_sequences = peptide_sequences.replace(r\"^ +| +$\", r\"\", regex=True)\n",
    "    name_index = peptide_sequences.columns.get_loc('Seq')\n",
    "    peptide_sequences.rename(columns={'Seq':'Name'}, inplace=True)\n",
    "    peptide_sequences = peptide_sequences.drop_duplicates(subset=['Name'])\n",
    "\n",
    "    # Create a dataframe for the extracted features for the peptide sequences.\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(len(peptide_sequences)):\n",
    "        df = pd.concat([df, inferenceSingleSeqence(peptide_sequences.iloc[i][name_index])])\n",
    "    df = df.drop(columns=['Seq','Helix','Turn','Sheet'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import, format, and drop duplicates.\n",
    "peptide_sequences = pd.read_csv('combined_hits.csv')\n",
    "peptide_sequences = peptide_sequences.replace(r\"^ +| +$\", r\"\", regex=True)\n",
    "name_index = peptide_sequences.columns.get_loc('Seq')\n",
    "peptide_sequences.rename(columns={'Seq':'Name'}, inplace=True)\n",
    "peptide_sequences = peptide_sequences.drop_duplicates(subset=['Name'])\n",
    "\n",
    "# Create a dataframe for the extracted features for the peptide sequences.\n",
    "\n",
    "data = inferenceSingleSeqence(peptide_sequences.iloc[0][name_index])\n",
    "data = data.drop(columns=['Seq','Helix','Turn','Sheet'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('antithrombin')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4e80bae16222c7bbbaf59498086a658280d426110f2738491d72ed8ab66400de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
