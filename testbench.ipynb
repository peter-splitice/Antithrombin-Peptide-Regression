{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing Dependencies\n",
    "\n",
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Dimensionality Reduction\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    " \n",
    "# Metrics\n",
    "from sklearn.metrics import matthews_corrcoef, mean_squared_error, accuracy_score, make_scorer\n",
    "\n",
    "# Model Persistence\n",
    "from joblib import dump, load\n",
    "\n",
    "# Plotter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Argument Parser\n",
    "import argparse\n",
    "\n",
    "# Write to a log file\n",
    "import logging\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the complete dataset.\n",
    "def import_data():\n",
    "    \"\"\"\n",
    "    Import the full dataset from the current path.  Also apply some of the necessary preprocessing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    None\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df:  Dataframe of the full KI training dataset, with any values above 50,000 removed.\n",
    "\n",
    "    base_range:  Contains the range of values within the dataframe for rescaling purposes.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Importing the full KI set into a dataframe.\n",
    "    path = os.getcwd()\n",
    "    df = pd.read_csv(path + '/PositivePeptide_Ki.csv')\n",
    "    \n",
    "\n",
    "    # Rescaling the dataframe in the log10 (-5,5) range.\n",
    "    df['KI (nM) rescaled'], base_range  = rescale(df['KI (nM)'], destination_interval=(-5,5))\n",
    "\n",
    "    return df, base_range\n",
    "\n",
    "## Logarithmically scalling the values.\n",
    "def rescale(array=np.array(0), destination_interval=(-5,5)):\n",
    "    \"\"\"\n",
    "    Rescale the KI values from nM to a log scale within the range of\n",
    "        a given destination interval.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    array:  A numpy array of KI values, in nM.\n",
    "\n",
    "    destination_interval: the interval that we set the range of the log scale to\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    array:  Transformed array into the log scale.\n",
    "    \n",
    "    saved_range:  The (min, max) range of the original given array.  Used if we need\n",
    "        to rescale back into \"KI (nM)\" form.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Rescaling the values and saving the initial range.\n",
    "    array = np.log(array)\n",
    "    saved_range = (array.min(), array.max())    \n",
    "    array = np.interp(array, saved_range, destination_interval)\n",
    "\n",
    "    return array, saved_range\n",
    "\n",
    "## Inverse of the rescale function to rescale the outputs.\n",
    "def unscale(array, destination_interval, source_interval=(-5,5)):\n",
    "    \"\"\"\n",
    "    Rescales an array of log-transformed values back into \"KI (nM)\" form.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    array:  A numpy array of KI values in log-transformed form.\n",
    "\n",
    "    destination_interval:  The original range of KI values.\n",
    "\n",
    "    source_interval: The current range of KI log transformed values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    array:  A numpy array of the KI values back in the original format.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Undoing the previous rescaling.\n",
    "    array = np.interp(array, source_interval, destination_interval)\n",
    "    array = np.exp(array)\n",
    "\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'auto',\n",
       " 'leaf_size': 5,\n",
       " 'metric': 'minkowski',\n",
       " 'metric_params': None,\n",
       " 'n_jobs': None,\n",
       " 'n_neighbors': 7,\n",
       " 'p': 2,\n",
       " 'weights': 'uniform'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 10\n",
    "\n",
    "df, _ = import_data()\n",
    "path = os.getcwd()\n",
    "\n",
    "df['Bucket'] = pd.cut(x=df['KI (nM)'], bins=(0, threshold, 4000, float('inf')), labels=(0,1,2))\n",
    "\n",
    "x = df[df.columns[1:573]]\n",
    "y = df['Bucket']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x)\n",
    "x = pd.DataFrame(scaler.transform(x), columns=df.columns[1:573])\n",
    "\n",
    "knn_params = {'n_neighbors': np.arange(1,41,2), 'weights': ['uniform', 'distance'], 'leaf_size': np.arange(5,41,2),\n",
    "                'p': [1, 2]}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "clf = GridSearchCV(knn,param_grid=knn_params,scoring=make_scorer(matthews_corrcoef),cv=5,\n",
    "                    return_train_score=True,n_jobs=-1)\n",
    "clf.fit(x,y)\n",
    "\n",
    "results = pd.DataFrame(clf.cv_results_)\n",
    "\n",
    "index = clf.best_index_\n",
    "\n",
    "params = results['params'][index]\n",
    "knn.set_params(**clf.best_params_)\n",
    "\n",
    "knn.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = [1, 2, 3, 4, clf.best_params_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['params']\n",
    "\n",
    "new = pd.DataFrame(columns=cols)\n",
    "\n",
    "new.loc[len(new)] = [knn.get_params()]\n",
    "new.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, '3']\n"
     ]
    }
   ],
   "source": [
    "number = 3\n",
    "\n",
    "newtester = [1, 2, '%i' %(number)]\n",
    "\n",
    "print(newtester)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('antithrombin')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4e80bae16222c7bbbaf59498086a658280d426110f2738491d72ed8ab66400de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
